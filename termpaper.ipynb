{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d772503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3844ef0",
   "metadata": {},
   "source": [
    "Part 1\n",
    "\n",
    "1. Write code to read all SCE files and merge them into a single DataFrame.\n",
    "2. Report the following statistics to get an idea of the sample size:\n",
    "1. Number of unique individuals in the dataset.\n",
    "2\n",
    "2. Number of observations (rows) in the dataset.\n",
    "3. Number of unique survey waves.\n",
    "4. The first and last dates observed in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bd260",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "136666b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>wid</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>female</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>black</th>\n",
       "      <th>couple</th>\n",
       "      <th>...</th>\n",
       "      <th>num_lit_q3</th>\n",
       "      <th>num_lit_q3_correct</th>\n",
       "      <th>num_lit_q5</th>\n",
       "      <th>num_lit_q5_correct</th>\n",
       "      <th>num_lit_q6</th>\n",
       "      <th>num_lit_q6_correct</th>\n",
       "      <th>num_lit_q8</th>\n",
       "      <th>num_lit_q8_correct</th>\n",
       "      <th>num_lit_q9</th>\n",
       "      <th>num_lit_q9_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70024705</td>\n",
       "      <td>201404</td>\n",
       "      <td>2014-04-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70024720</td>\n",
       "      <td>201404</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70024744</td>\n",
       "      <td>201404</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70024764</td>\n",
       "      <td>201404</td>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70024781</td>\n",
       "      <td>201404</td>\n",
       "      <td>2014-04-10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176096</th>\n",
       "      <td>75023169</td>\n",
       "      <td>202409</td>\n",
       "      <td>2024-09-19</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176097</th>\n",
       "      <td>75023181</td>\n",
       "      <td>202409</td>\n",
       "      <td>2024-09-07</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176098</th>\n",
       "      <td>75023187</td>\n",
       "      <td>202409</td>\n",
       "      <td>2024-09-19</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176099</th>\n",
       "      <td>75023188</td>\n",
       "      <td>202409</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176100</th>\n",
       "      <td>75023201</td>\n",
       "      <td>202409</td>\n",
       "      <td>2024-09-20</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176101 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userid     wid       date  weight  female  educ   age  hispanic  \\\n",
       "0       70024705  201404 2014-04-03     1.0     0.0   3.0  23.0       0.0   \n",
       "1       70024720  201404 2014-04-02     0.5     0.0   4.0  65.0       0.0   \n",
       "2       70024744  201404 2014-04-02     0.6     0.0   4.0  52.0       0.0   \n",
       "3       70024764  201404 2014-04-08     0.4     1.0   4.0  46.0       0.0   \n",
       "4       70024781  201404 2014-04-10     0.8     1.0   3.0  61.0       0.0   \n",
       "...          ...     ...        ...     ...     ...   ...   ...       ...   \n",
       "176096  75023169  202409 2024-09-19     2.5     1.0   1.0  23.0       0.0   \n",
       "176097  75023181  202409 2024-09-07     1.1     1.0   3.0  53.0       1.0   \n",
       "176098  75023187  202409 2024-09-19     0.8     0.0   4.0  51.0       0.0   \n",
       "176099  75023188  202409 2024-09-03     0.7     1.0   4.0  53.0       0.0   \n",
       "176100  75023201  202409 2024-09-20     2.3     1.0   2.0  43.0       0.0   \n",
       "\n",
       "        black  couple  ...  num_lit_q3  num_lit_q3_correct  num_lit_q5  \\\n",
       "0         0.0     NaN  ...         NaN                 NaN         NaN   \n",
       "1         0.0     NaN  ...         NaN                 NaN         NaN   \n",
       "2         0.0     NaN  ...         NaN                 NaN         NaN   \n",
       "3         0.0     NaN  ...         NaN                 NaN         NaN   \n",
       "4         0.0     NaN  ...         NaN                 NaN         NaN   \n",
       "...       ...     ...  ...         ...                 ...         ...   \n",
       "176096    1.0     0.0  ...         2.0                 0.0        20.0   \n",
       "176097    1.0     1.0  ...        10.0                 1.0      1000.0   \n",
       "176098    1.0     0.0  ...       100.0                 0.0       100.0   \n",
       "176099    0.0     0.0  ...        10.0                 1.0       100.0   \n",
       "176100    0.0     1.0  ...        10.0                 1.0       100.0   \n",
       "\n",
       "        num_lit_q5_correct  num_lit_q6  num_lit_q6_correct  num_lit_q8  \\\n",
       "0                      NaN         NaN                 NaN         NaN   \n",
       "1                      NaN         NaN                 NaN         NaN   \n",
       "2                      NaN         NaN                 NaN         NaN   \n",
       "3                      NaN         NaN                 NaN         NaN   \n",
       "4                      NaN         NaN                 NaN         NaN   \n",
       "...                    ...         ...                 ...         ...   \n",
       "176096                 0.0         1.0                 0.0         2.0   \n",
       "176097                 0.0         4.0                 0.0         1.0   \n",
       "176098                 1.0         5.0                 1.0         3.0   \n",
       "176099                 1.0         5.0                 1.0         3.0   \n",
       "176100                 1.0         5.0                 1.0         1.0   \n",
       "\n",
       "        num_lit_q8_correct  num_lit_q9  num_lit_q9_correct  \n",
       "0                      NaN         NaN                 NaN  \n",
       "1                      NaN         NaN                 NaN  \n",
       "2                      NaN         NaN                 NaN  \n",
       "3                      NaN         NaN                 NaN  \n",
       "4                      NaN         NaN                 NaN  \n",
       "...                    ...         ...                 ...  \n",
       "176096                 0.0         2.0                 1.0  \n",
       "176097                 0.0         1.0                 0.0  \n",
       "176098                 1.0         2.0                 1.0  \n",
       "176099                 1.0         2.0                 1.0  \n",
       "176100                 0.0         2.0                 1.0  \n",
       "\n",
       "[176101 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in files using glob library and for loop\n",
    "files = glob.glob('../TECH2-GROUP-TERM-PAPER/data/*.csv')\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep= ';', parse_dates = ['date'])\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ec9d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: data\\SCE-Apr-2014.csv\n",
      "Loading data from: data\\SCE-Apr-2015.csv\n",
      "Loading data from: data\\SCE-Apr-2016.csv\n",
      "Loading data from: data\\SCE-Apr-2017.csv\n",
      "Loading data from: data\\SCE-Apr-2018.csv\n",
      "Loading data from: data\\SCE-Apr-2019.csv\n",
      "Loading data from: data\\SCE-Apr-2020.csv\n",
      "Loading data from: data\\SCE-Apr-2021.csv\n",
      "Loading data from: data\\SCE-Apr-2022.csv\n",
      "Loading data from: data\\SCE-Apr-2023.csv\n",
      "Loading data from: data\\SCE-Apr-2024.csv\n",
      "Loading data from: data\\SCE-Apr-2024.csv\n",
      "Loading data from: data\\SCE-Dec-2013.csv\n",
      "Loading data from: data\\SCE-Dec-2014.csv\n",
      "Loading data from: data\\SCE-Dec-2015.csv\n",
      "Loading data from: data\\SCE-Dec-2016.csv\n",
      "Loading data from: data\\SCE-Dec-2017.csv\n",
      "Loading data from: data\\SCE-Dec-2018.csv\n",
      "Loading data from: data\\SCE-Dec-2019.csv\n",
      "Loading data from: data\\SCE-Dec-2020.csv\n",
      "Loading data from: data\\SCE-Dec-2021.csv\n",
      "Loading data from: data\\SCE-Dec-2022.csv\n",
      "Loading data from: data\\SCE-Dec-2023.csv\n",
      "Loading data from: data\\SCE-Dec-2024.csv\n",
      "Loading data from: data\\SCE-Dec-2024.csv\n",
      "Loading data from: data\\SCE-Feb-2014.csv\n",
      "Loading data from: data\\SCE-Feb-2015.csv\n",
      "Loading data from: data\\SCE-Feb-2016.csv\n",
      "Loading data from: data\\SCE-Feb-2017.csv\n",
      "Loading data from: data\\SCE-Feb-2018.csv\n",
      "Loading data from: data\\SCE-Feb-2019.csv\n",
      "Loading data from: data\\SCE-Feb-2020.csv\n",
      "Loading data from: data\\SCE-Feb-2021.csv\n",
      "Loading data from: data\\SCE-Feb-2022.csv\n",
      "Loading data from: data\\SCE-Feb-2023.csv\n",
      "Loading data from: data\\SCE-Feb-2024.csv\n",
      "Loading data from: data\\SCE-Feb-2024.csv\n",
      "Loading data from: data\\SCE-Jan-2014.csv\n",
      "Loading data from: data\\SCE-Jan-2015.csv\n",
      "Loading data from: data\\SCE-Jan-2016.csv\n",
      "Loading data from: data\\SCE-Jan-2017.csv\n",
      "Loading data from: data\\SCE-Jan-2018.csv\n",
      "Loading data from: data\\SCE-Jan-2019.csv\n",
      "Loading data from: data\\SCE-Jan-2020.csv\n",
      "Loading data from: data\\SCE-Jan-2021.csv\n",
      "Loading data from: data\\SCE-Jan-2022.csv\n",
      "Loading data from: data\\SCE-Jan-2023.csv\n",
      "Loading data from: data\\SCE-Jan-2024.csv\n",
      "Loading data from: data\\SCE-Jan-2024.csv\n",
      "Loading data from: data\\SCE-Jul-2013.csv\n",
      "Loading data from: data\\SCE-Jul-2014.csv\n",
      "Loading data from: data\\SCE-Jul-2015.csv\n",
      "Loading data from: data\\SCE-Jul-2016.csv\n",
      "Loading data from: data\\SCE-Jul-2017.csv\n",
      "Loading data from: data\\SCE-Jul-2018.csv\n",
      "Loading data from: data\\SCE-Jul-2019.csv\n",
      "Loading data from: data\\SCE-Jul-2020.csv\n",
      "Loading data from: data\\SCE-Jul-2021.csv\n",
      "Loading data from: data\\SCE-Jul-2022.csv\n",
      "Loading data from: data\\SCE-Jul-2023.csv\n",
      "Loading data from: data\\SCE-Jul-2024.csv\n",
      "Loading data from: data\\SCE-Jul-2024.csv\n",
      "Loading data from: data\\SCE-Jun-2013.csv\n",
      "Loading data from: data\\SCE-Jun-2014.csv\n",
      "Loading data from: data\\SCE-Jun-2015.csv\n",
      "Loading data from: data\\SCE-Jun-2016.csv\n",
      "Loading data from: data\\SCE-Jun-2017.csv\n",
      "Loading data from: data\\SCE-Jun-2018.csv\n",
      "Loading data from: data\\SCE-Jun-2019.csv\n",
      "Loading data from: data\\SCE-Jun-2020.csv\n",
      "Loading data from: data\\SCE-Jun-2021.csv\n",
      "Loading data from: data\\SCE-Jun-2022.csv\n",
      "Loading data from: data\\SCE-Jun-2023.csv\n",
      "Loading data from: data\\SCE-Jun-2024.csv\n",
      "Loading data from: data\\SCE-Jun-2024.csv\n",
      "Loading data from: data\\SCE-Mar-2014.csv\n",
      "Loading data from: data\\SCE-Mar-2015.csv\n",
      "Loading data from: data\\SCE-Mar-2016.csv\n",
      "Loading data from: data\\SCE-Mar-2017.csv\n",
      "Loading data from: data\\SCE-Mar-2018.csv\n",
      "Loading data from: data\\SCE-Mar-2019.csv\n",
      "Loading data from: data\\SCE-Mar-2020.csv\n",
      "Loading data from: data\\SCE-Mar-2021.csv\n",
      "Loading data from: data\\SCE-Mar-2022.csv\n",
      "Loading data from: data\\SCE-Mar-2023.csv\n",
      "Loading data from: data\\SCE-Mar-2024.csv\n",
      "Loading data from: data\\SCE-Mar-2024.csv\n",
      "Loading data from: data\\SCE-May-2014.csv\n",
      "Loading data from: data\\SCE-May-2015.csv\n",
      "Loading data from: data\\SCE-May-2016.csv\n",
      "Loading data from: data\\SCE-May-2017.csv\n",
      "Loading data from: data\\SCE-May-2018.csv\n",
      "Loading data from: data\\SCE-May-2019.csv\n",
      "Loading data from: data\\SCE-May-2020.csv\n",
      "Loading data from: data\\SCE-May-2021.csv\n",
      "Loading data from: data\\SCE-May-2022.csv\n",
      "Loading data from: data\\SCE-May-2023.csv\n",
      "Loading data from: data\\SCE-May-2024.csv\n",
      "Loading data from: data\\SCE-May-2024.csv\n",
      "Loading data from: data\\SCE-Nov-2013.csv\n",
      "Loading data from: data\\SCE-Nov-2014.csv\n",
      "Loading data from: data\\SCE-Nov-2015.csv\n",
      "Loading data from: data\\SCE-Nov-2016.csv\n",
      "Loading data from: data\\SCE-Nov-2017.csv\n",
      "Loading data from: data\\SCE-Nov-2018.csv\n",
      "Loading data from: data\\SCE-Nov-2019.csv\n",
      "Loading data from: data\\SCE-Nov-2020.csv\n",
      "Loading data from: data\\SCE-Nov-2021.csv\n",
      "Loading data from: data\\SCE-Nov-2022.csv\n",
      "Loading data from: data\\SCE-Nov-2023.csv\n",
      "Loading data from: data\\SCE-Nov-2024.csv\n",
      "Loading data from: data\\SCE-Nov-2024.csv\n",
      "Loading data from: data\\SCE-Oct-2013.csv\n",
      "Loading data from: data\\SCE-Oct-2014.csv\n",
      "Loading data from: data\\SCE-Oct-2015.csv\n",
      "Loading data from: data\\SCE-Oct-2016.csv\n",
      "Loading data from: data\\SCE-Oct-2017.csv\n",
      "Loading data from: data\\SCE-Oct-2018.csv\n",
      "Loading data from: data\\SCE-Oct-2019.csv\n",
      "Loading data from: data\\SCE-Oct-2020.csv\n",
      "Loading data from: data\\SCE-Oct-2021.csv\n",
      "Loading data from: data\\SCE-Oct-2022.csv\n",
      "Loading data from: data\\SCE-Oct-2023.csv\n",
      "Loading data from: data\\SCE-Oct-2024.csv\n",
      "Loading data from: data\\SCE-Oct-2024.csv\n",
      "Loading data from: data\\SCE-Sep-2013.csv\n",
      "Loading data from: data\\SCE-Sep-2014.csv\n",
      "Loading data from: data\\SCE-Sep-2015.csv\n",
      "Loading data from: data\\SCE-Sep-2016.csv\n",
      "Loading data from: data\\SCE-Sep-2017.csv\n",
      "Loading data from: data\\SCE-Sep-2018.csv\n",
      "Loading data from: data\\SCE-Sep-2019.csv\n",
      "Loading data from: data\\SCE-Sep-2020.csv\n",
      "Loading data from: data\\SCE-Sep-2021.csv\n",
      "Loading data from: data\\SCE-Sep-2022.csv\n",
      "Loading data from: data\\SCE-Sep-2023.csv\n",
      "Loading data from: data\\SCE-Sep-2024.csv\n",
      "Loading data from: data\\SCE-Sep-2024.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>wid</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>female</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>black</th>\n",
       "      <th>couple</th>\n",
       "      <th>...</th>\n",
       "      <th>num_lit_q3_correct</th>\n",
       "      <th>num_lit_q5</th>\n",
       "      <th>num_lit_q5_correct</th>\n",
       "      <th>num_lit_q6</th>\n",
       "      <th>num_lit_q6_correct</th>\n",
       "      <th>num_lit_q8</th>\n",
       "      <th>num_lit_q8_correct</th>\n",
       "      <th>num_lit_q9</th>\n",
       "      <th>num_lit_q9_correct</th>\n",
       "      <th>userid;wid;date;weight;female;educ;age;hispanic;black;couple;num_kids;owner;inflation;house_price_change;prob_stocks_up;num_lit_q1;num_lit_q1_correct;num_lit_q2;num_lit_q2_correct;num_lit_q3;num_lit_q3_correct;num_lit_q5;num_lit_q5_correct;num_lit_q6;num_lit_q6_correct;num_lit_q8;num_lit_q8_correct;num_lit_q9;num_lit_q9_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70024705.0</td>\n",
       "      <td>201404.0</td>\n",
       "      <td>2014-04-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70024720.0</td>\n",
       "      <td>201404.0</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70024744.0</td>\n",
       "      <td>201404.0</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70024764.0</td>\n",
       "      <td>201404.0</td>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70024781.0</td>\n",
       "      <td>201404.0</td>\n",
       "      <td>2014-04-10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172431</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75023169;202409;2024-09-19;2.5;1.0;1.0;23.0;0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172432</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75023181;202409;2024-09-07;1.1;1.0;3.0;53.0;1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172433</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75023187;202409;2024-09-19;0.8;0.0;4.0;51.0;0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172434</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75023188;202409;2024-09-03;0.7;1.0;4.0;53.0;0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172435</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75023201;202409;2024-09-20;2.3;1.0;2.0;43.0;0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172436 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            userid       wid       date  weight  female  educ   age  hispanic  \\\n",
       "0       70024705.0  201404.0 2014-04-03     1.0     0.0   3.0  23.0       0.0   \n",
       "1       70024720.0  201404.0 2014-04-02     0.5     0.0   4.0  65.0       0.0   \n",
       "2       70024744.0  201404.0 2014-04-02     0.6     0.0   4.0  52.0       0.0   \n",
       "3       70024764.0  201404.0 2014-04-08     0.4     1.0   4.0  46.0       0.0   \n",
       "4       70024781.0  201404.0 2014-04-10     0.8     1.0   3.0  61.0       0.0   \n",
       "...            ...       ...        ...     ...     ...   ...   ...       ...   \n",
       "172431         NaN       NaN        NaT     NaN     NaN   NaN   NaN       NaN   \n",
       "172432         NaN       NaN        NaT     NaN     NaN   NaN   NaN       NaN   \n",
       "172433         NaN       NaN        NaT     NaN     NaN   NaN   NaN       NaN   \n",
       "172434         NaN       NaN        NaT     NaN     NaN   NaN   NaN       NaN   \n",
       "172435         NaN       NaN        NaT     NaN     NaN   NaN   NaN       NaN   \n",
       "\n",
       "        black  couple  ...  num_lit_q3_correct  num_lit_q5  \\\n",
       "0         0.0     NaN  ...                 NaN         NaN   \n",
       "1         0.0     NaN  ...                 NaN         NaN   \n",
       "2         0.0     NaN  ...                 NaN         NaN   \n",
       "3         0.0     NaN  ...                 NaN         NaN   \n",
       "4         0.0     NaN  ...                 NaN         NaN   \n",
       "...       ...     ...  ...                 ...         ...   \n",
       "172431    NaN     NaN  ...                 NaN         NaN   \n",
       "172432    NaN     NaN  ...                 NaN         NaN   \n",
       "172433    NaN     NaN  ...                 NaN         NaN   \n",
       "172434    NaN     NaN  ...                 NaN         NaN   \n",
       "172435    NaN     NaN  ...                 NaN         NaN   \n",
       "\n",
       "        num_lit_q5_correct  num_lit_q6  num_lit_q6_correct  num_lit_q8  \\\n",
       "0                      NaN         NaN                 NaN         NaN   \n",
       "1                      NaN         NaN                 NaN         NaN   \n",
       "2                      NaN         NaN                 NaN         NaN   \n",
       "3                      NaN         NaN                 NaN         NaN   \n",
       "4                      NaN         NaN                 NaN         NaN   \n",
       "...                    ...         ...                 ...         ...   \n",
       "172431                 NaN         NaN                 NaN         NaN   \n",
       "172432                 NaN         NaN                 NaN         NaN   \n",
       "172433                 NaN         NaN                 NaN         NaN   \n",
       "172434                 NaN         NaN                 NaN         NaN   \n",
       "172435                 NaN         NaN                 NaN         NaN   \n",
       "\n",
       "        num_lit_q8_correct  num_lit_q9  num_lit_q9_correct  \\\n",
       "0                      NaN         NaN                 NaN   \n",
       "1                      NaN         NaN                 NaN   \n",
       "2                      NaN         NaN                 NaN   \n",
       "3                      NaN         NaN                 NaN   \n",
       "4                      NaN         NaN                 NaN   \n",
       "...                    ...         ...                 ...   \n",
       "172431                 NaN         NaN                 NaN   \n",
       "172432                 NaN         NaN                 NaN   \n",
       "172433                 NaN         NaN                 NaN   \n",
       "172434                 NaN         NaN                 NaN   \n",
       "172435                 NaN         NaN                 NaN   \n",
       "\n",
       "        userid;wid;date;weight;female;educ;age;hispanic;black;couple;num_kids;owner;inflation;house_price_change;prob_stocks_up;num_lit_q1;num_lit_q1_correct;num_lit_q2;num_lit_q2_correct;num_lit_q3;num_lit_q3_correct;num_lit_q5;num_lit_q5_correct;num_lit_q6;num_lit_q6_correct;num_lit_q8;num_lit_q8_correct;num_lit_q9;num_lit_q9_correct  \n",
       "0                                                     NaN                                                                                                                                                                                                                                                                                          \n",
       "1                                                     NaN                                                                                                                                                                                                                                                                                          \n",
       "2                                                     NaN                                                                                                                                                                                                                                                                                          \n",
       "3                                                     NaN                                                                                                                                                                                                                                                                                          \n",
       "4                                                     NaN                                                                                                                                                                                                                                                                                          \n",
       "...                                                   ...                                                                                                                                                                                                                                                                                          \n",
       "172431  75023169;202409;2024-09-19;2.5;1.0;1.0;23.0;0....                                                                                                                                                                                                                                                                                          \n",
       "172432  75023181;202409;2024-09-07;1.1;1.0;3.0;53.0;1....                                                                                                                                                                                                                                                                                          \n",
       "172433  75023187;202409;2024-09-19;0.8;0.0;4.0;51.0;0....                                                                                                                                                                                                                                                                                          \n",
       "172434  75023188;202409;2024-09-03;0.7;1.0;4.0;53.0;0....                                                                                                                                                                                                                                                                                          \n",
       "172435  75023201;202409;2024-09-20;2.3;1.0;2.0;43.0;0....                                                                                                                                                                                                                                                                                          \n",
       "\n",
       "[172436 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "#creates\n",
    "years=np.arange(2013,2025)\n",
    "months=('Apr','Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep')\n",
    "\n",
    "# use nested for loops\n",
    "\n",
    "data = []\n",
    "for month in months:\n",
    "    for year in years:\n",
    "    # File name for current file\n",
    "        fn = f'SCE-{month}-{year}.csv'\n",
    "\n",
    "    # Join data folder + filename to get path to CSV file\n",
    "        path = os.path.join('data', fn)\n",
    "    \n",
    "        \n",
    "        if os.path.exists(path):\n",
    "         \n",
    "         print(f\"Loading data from: {path}\")\n",
    "         df = pd.read_csv(path, sep=';', parse_dates=['date'])\n",
    "         data.append(df)\n",
    "\n",
    "\n",
    "    print(f'Loading data from: {path}')\n",
    "    \n",
    "    # Load decade data\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    data.append(df)\n",
    "\n",
    "comb_df=pd.concat(data, ignore_index=True)\n",
    "comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3d133f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniqe induviduals: 22914\n",
      "number of observations: 172436\n",
      "number of suvey waves: 172436\n",
      "The first date: 2013-06-01\n",
      "The last date: 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "print(f'number of uniqe induviduals:', comb_df['userid'].nunique())\n",
    "print(f'number of observations:', len(comb_df))\n",
    "print(f'number of suvey waves:',len(comb_df['wid']))\n",
    "print(f'The first date:', comb_df['date'].min().date())\n",
    "print(f'The last date:', comb_df['date'].max().date()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40edaf",
   "metadata": {},
   "source": [
    "Part 2\n",
    "\n",
    "1. The numeracy questions are only asked the first time a respondent enters the survey and are\n",
    "missing in subsequent waves. For each individual, fill in the missing numeracy variables\n",
    "(num_lit_X_correct where X is a number) using the values from the first observation.\n",
    "2. Drop all observations (rows) with missing values for the following variables:\n",
    "1. Demographic information (gender, age, education)\n",
    "2. The three expectations questions about inflation, house price changes, and the stock market\n",
    "3. The seven numeracy questions (after you have forward-filled nonmissing values in step 1!)\n",
    "Report the number of observations dropped at each step.\n",
    "3. Drop outliers (implausibly small or large values). For each expectations response:\n",
    "1. Compute the 0.1th percentile (0.001 quantile) and drop observations below this value.\n",
    "2. Compute the 99.9th percentile (0.999 quantile) and drop observations above this value.\n",
    "Report the number of observations dropped at each step.\n",
    "4. Create a new column college equal to 1 if an individual has at least a bachelor’s degree, and 0\n",
    "otherwise.\n",
    "5. For each individual, compute the total number of correct numeracy responses and report the\n",
    "fraction of individuals with 0, 1, . . . , 7 correct responses (e.g., 36.2% of individuals got all 7 right).\n",
    "Create a new column num_lit_high (“high numerical literacy”) equal to 1 if an individual had\n",
    "more correct responses than the median, and 0 otherwise.\n",
    "6. Report the same sample statistics as in Part 1 for the final data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f478c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6feea97a",
   "metadata": {},
   "source": [
    "Part 3\n",
    "\n",
    "With the processed data set in hand, you now turn to answering the governor’s first question: how do\n",
    "expectations differ by gender, education, and numeracy?\n",
    "For this part, perform the same analysis three times, each time splitting the sample by a different\n",
    "variable:\n",
    "1. Males vs. females\n",
    "2. Non-college vs. college\n",
    "3. Low vs. high numeracy\n",
    "\n",
    "For each part,\n",
    "1. Compute the average for each expectations variable (inflation, house prices, stock market) sepa-\n",
    "rately for each group (males and females, non-college and college, etc.)\n",
    "2. Create a figure with three panels (one per expectations variable) which depicts these group\n",
    "averages as bar charts.\n",
    "3\n",
    "The complete analysis should produce three figures, each with three panels, each panel containing two\n",
    "bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b3b415",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'female'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1. average for each expectations variable\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Males Vs. Females\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create a function to calculate and print the average variables \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_gender = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfemale\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdf_gender_calculation\u001b[39m(variable):\n\u001b[32m      7\u001b[39m     variable_neat = variable.replace(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m).upper()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sophi\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\frame.py:9190\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9196\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sophi\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1330\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1327\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1330\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1341\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sophi\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'female'"
     ]
    }
   ],
   "source": [
    "# 1. average for each expectations variable\n",
    "# Males Vs. Females\n",
    "\n",
    "# Create a function to calculate and print the average variables \n",
    "df_gender = df.groupby(['female'])\n",
    "def df_gender_calculation(variable):\n",
    "    variable_neat = variable.replace('_', ' ').upper()\n",
    "    variable_average = round(df_gender[variable].mean(),1)\n",
    "    variable_average = variable_average.rename({0.0: 'Male', 1.0: 'Female'})\n",
    "    variabledc = variable_average.to_dict()\n",
    "    for key, value in variabledc.items(): \n",
    "        print(f'The average answer for {variable_neat} from the {key} group is {value}.')\n",
    "\n",
    "df_gender_calculation(variable = 'inflation')\n",
    "print('')\n",
    "df_gender_calculation(variable = 'house_price_change')\n",
    "print('')\n",
    "df_gender_calculation(variable = 'prob_stocks_up')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f709a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average answer for INFLATION from the college educated group is 5.5.\n",
      "The average answer for INFLATION from the non college educated group is 16.3.\n",
      "\n",
      "The average answer for HOUSE PRICE CHANGE from the college educated group is 5.1.\n",
      "The average answer for HOUSE PRICE CHANGE from the non college educated group is 8.9.\n",
      "\n",
      "The average answer for PROB STOCKS UP from the college educated group is 43.0.\n",
      "The average answer for PROB STOCKS UP from the non college educated group is 34.3.\n"
     ]
    }
   ],
   "source": [
    "# non-college and college\n",
    "df_college = df[df['educ']>2]\n",
    "df_non_college= df[df['educ']<2]\n",
    "\n",
    "def df_college_calculation(variable):\n",
    "    variable_neat = variable.replace('_', ' ').upper()\n",
    "    df_educ ={}\n",
    "    variable_averagec = round(df_college[variable].mean(), 1)\n",
    "    variable_averagenc = round(df_non_college[variable].mean(),1)\n",
    "    df_educ['college educated'] = variable_averagec\n",
    "    df_educ['non college educated'] = variable_averagenc\n",
    "    for key, value in df_educ.items():\n",
    "        print(f'The average answer for {variable_neat} from the {key} group is {value}.')\n",
    "\n",
    "df_college_calculation(variable = 'inflation')\n",
    "print('')\n",
    "df_college_calculation(variable = 'house_price_change')\n",
    "print('')\n",
    "df_college_calculation(variable = 'prob_stocks_up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564be27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average answer for INFLATION from the high numeracy group is 8.2.\n",
      "The average answer for INFLATION from the low numeracy group is 14.1.\n",
      " \n",
      "The average answer for HOUSE PRICE CHANGE from the high numeracy group is 6.2.\n",
      "The average answer for HOUSE PRICE CHANGE from the low numeracy group is 12.2.\n",
      "\n",
      "The average answer for PROB STOCKS UP from the high numeracy group is 47.8.\n",
      "The average answer for PROB STOCKS UP from the low numeracy group is 41.5.\n"
     ]
    }
   ],
   "source": [
    "#low vs high numeracy\n",
    "# calculate average numeracy for each person\n",
    "columns= ['num_lit_q1_correct',\n",
    " 'num_lit_q2_correct',\n",
    " 'num_lit_q3_correct',\n",
    " 'num_lit_q5_correct',\n",
    " 'num_lit_q6_correct',\n",
    " 'num_lit_q8_correct',\n",
    " 'num_lit_q9_correct']\n",
    "df['Numeracy'] = df[columns].mean(axis = 1)\n",
    "\n",
    "#divide between high and low numeracy\n",
    "df_high = df[df['Numeracy']>0.5]\n",
    "df_low = df[df['Numeracy']<0.5]\n",
    "\n",
    "#function to calculate average for each variable\n",
    "def df_numeracy_calculation(variable):\n",
    "    variable_neat = variable.replace('_', ' ').upper()\n",
    "    df_num ={}\n",
    "    variable_averageh = round(df_high[variable].mean(), 1)\n",
    "    variable_averagel = round(df_low[variable].mean(),1)\n",
    "    df_num['high numeracy'] = variable_averageh\n",
    "    df_num['low numeracy'] = variable_averagel\n",
    "    for key, value in df_num.items():\n",
    "        print(f'The average answer for {variable_neat} from the {key} group is {value}.')\n",
    "\n",
    "df_numeracy_calculation(variable = 'inflation')\n",
    "print(' ')\n",
    "df_numeracy_calculation(variable = 'house_price_change')\n",
    "print('')\n",
    "df_numeracy_calculation(variable = 'prob_stocks_up')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21f9a8",
   "metadata": {},
   "source": [
    "Part 4\n",
    "\n",
    "To answer the governor’s second set of questions, you need to investigate how average expectations\n",
    "evolved over time for the period of 2015-2024 covered by the sample.\n",
    "For each grouping variable (female, college, num_lit_high):\n",
    "1. Collapse the data to monthly averages for each of the expectation variables (inflation, house prices,\n",
    "stock market) for each group (e.g., for males vs. females).\n",
    "2. Create a figure with three vertically stacked panels (one panel per expectation variable). Each\n",
    "panel should show the group time series (two series per panel, e.g., males vs. females) with time\n",
    "on the x-axis.\n",
    "3. The governor wants to know how expectations reacted to important geopolitical events. Add\n",
    "vertical lines and annotations to each panel indicating the following events:\n",
    "• Trump elected US president for the first time (November 8, 2016)\n",
    "• COVID-19 pandemic goes global (February 1, 2020)\n",
    "• Biden elected US president (November 3, 2020)\n",
    "• Russia’s full-scale invasion of Ukraine (February 24, 2022)\n",
    "• Nobel Prize in Literature awarded to Jon Fosse (October 3, 2023)\n",
    "• Trump elected US president for the second time (November 5, 2024)\n",
    "Which events had sizeable effects on expectations? Can you detect differences in how different\n",
    "groups adjusted their expectations?\n",
    "The complete analysis should produce three figures, each with three panels, each panel containing two\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095df410",
   "metadata": {},
   "source": [
    "Part 5\n",
    "\n",
    "Finally, the governor is interested in whether people’s expectations indicate realized future inflation or\n",
    "simply reflect past inflation experienced when answering the survey.\n",
    "To answer this question, you first need to obtain data on realized inflation. A colleague has already\n",
    "downloaded data on the level of the Consumer Price Index (CPI) from FRED and stored it as a CSV file\n",
    "in the data/ folder.\n",
    "1. First, compare expectations to realized future inflation:\n",
    "1. Using this monthly CPI data, compute the realized inflation over the next 12 months; i.e., for\n",
    "each month t compute the forward-looking annual inflation as\n",
    "In f lationt = CPIt+12 −CPIt\n",
    "CPIt\n",
    "×100\n",
    "2. Merge this inflation measure with the monthly averages by gender from Part 4. Specifically,\n",
    "match the average expected inflation by gender i in month t from the SCE, Ex pIn f lationit,\n",
    "with the forward-looking inflation measure In f lationt from the CPI data.\n",
    "3. Create a figure with two panels (one per gender), each showing a scatter plot of realized\n",
    "future inflation (y-axis) versus average expected inflation by gender.\n",
    "Compute the correlation between expected and realized inflation for each gender and add\n",
    "the correlation coefficient as text to the corresponding panel.\n",
    "4\n",
    "2. Repeat steps 1–3, but instead of forward-looking inflation, compute realized inflation over the past\n",
    "12 months:\n",
    "In f lationt = CPIt −CPIt−12\n",
    "CPIt−12\n",
    "×100\n",
    "Do you find differences in these correlation coefficients? What do these results say about how individuals\n",
    "form beliefs about inflation? Are there notable gender differences?\n",
    "Note: In this part, use monthly data only; individual-level SCE data is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290b49d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
