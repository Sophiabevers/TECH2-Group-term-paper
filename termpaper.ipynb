{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d772503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3844ef0",
   "metadata": {},
   "source": [
    "Part 1\n",
    "\n",
    "1. Write code to read all SCE files and merge them into a single DataFrame.\n",
    "2. Report the following statistics to get an idea of the sample size:\n",
    "1. Number of unique individuals in the dataset.\n",
    "2\n",
    "2. Number of observations (rows) in the dataset.\n",
    "3. Number of unique survey waves.\n",
    "4. The first and last dates observed in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bd260",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "136666b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m dfs = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     dfs.append(df)\n\u001b[32m      7\u001b[39m df = pd.concat(dfs, ignore_index = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olav\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olav\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olav\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olav\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olav\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:161\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m    155\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate_usecols_names(\n\u001b[32m    156\u001b[39m             usecols,\n\u001b[32m    157\u001b[39m             \u001b[38;5;28mself\u001b[39m.names,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    158\u001b[39m         )\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mself\u001b[39m._set_noconvert_columns()\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olav\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:243\u001b[39m, in \u001b[36mParserBase._validate_parse_dates_presence\u001b[39m\u001b[34m(self, columns)\u001b[39m\n\u001b[32m    233\u001b[39m missing_cols = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    234\u001b[39m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m    235\u001b[39m         {\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m     )\n\u001b[32m    241\u001b[39m )\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    244\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing column provided to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mparse_dates\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m     )\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    248\u001b[39m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[32m    250\u001b[39m ]\n",
      "\u001b[31mValueError\u001b[39m: Missing column provided to 'parse_dates': 'date'"
     ]
    }
   ],
   "source": [
    "#read in files using glob library and for loop\n",
    "files = glob.glob('../TECH2-GROUP-TERM-PAPER/data/*.csv')\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep= ';', parse_dates = ['date'])\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d133f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniqe induviduals: 22914\n",
      "number of observations: 172436\n",
      "number of suvey waves: 172436\n",
      "The first date: 2013-06-01\n",
      "The last date: 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "print(f'number of uniqe induviduals:', comb_df['userid'].nunique())\n",
    "print(f'number of observations:', len(comb_df))\n",
    "print(f'number of suvey waves:',len(comb_df['wid']))\n",
    "print(f'The first date:', comb_df['date'].min().date())\n",
    "print(f'The last date:', comb_df['date'].max().date()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40edaf",
   "metadata": {},
   "source": [
    "Part 2\n",
    "\n",
    "1. The numeracy questions are only asked the first time a respondent enters the survey and are\n",
    "missing in subsequent waves. For each individual, fill in the missing numeracy variables\n",
    "(num_lit_X_correct where X is a number) using the values from the first observation.\n",
    "2. Drop all observations (rows) with missing values for the following variables:\n",
    "1. Demographic information (gender, age, education)\n",
    "2. The three expectations questions about inflation, house price changes, and the stock market\n",
    "3. The seven numeracy questions (after you have forward-filled nonmissing values in step 1!)\n",
    "Report the number of observations dropped at each step.\n",
    "3. Drop outliers (implausibly small or large values). For each expectations response:\n",
    "1. Compute the 0.1th percentile (0.001 quantile) and drop observations below this value.\n",
    "2. Compute the 99.9th percentile (0.999 quantile) and drop observations above this value.\n",
    "Report the number of observations dropped at each step.\n",
    "4. Create a new column college equal to 1 if an individual has at least a bachelor’s degree, and 0\n",
    "otherwise.\n",
    "5. For each individual, compute the total number of correct numeracy responses and report the\n",
    "fraction of individuals with 0, 1, . . . , 7 correct responses (e.g., 36.2% of individuals got all 7 right).\n",
    "Create a new column num_lit_high (“high numerical literacy”) equal to 1 if an individual had\n",
    "more correct responses than the median, and 0 otherwise.\n",
    "6. Report the same sample statistics as in Part 1 for the final data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f478c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6feea97a",
   "metadata": {},
   "source": [
    "Part 3\n",
    "\n",
    "With the processed data set in hand, you now turn to answering the governor’s first question: how do\n",
    "expectations differ by gender, education, and numeracy?\n",
    "For this part, perform the same analysis three times, each time splitting the sample by a different\n",
    "variable:\n",
    "1. Males vs. females\n",
    "2. Non-college vs. college\n",
    "3. Low vs. high numeracy\n",
    "\n",
    "For each part,\n",
    "1. Compute the average for each expectations variable (inflation, house prices, stock market) sepa-\n",
    "rately for each group (males and females, non-college and college, etc.)\n",
    "2. Create a figure with three panels (one per expectations variable) which depicts these group\n",
    "averages as bar charts.\n",
    "3\n",
    "The complete analysis should produce three figures, each with three panels, each panel containing two\n",
    "bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average answer for INFLATION from the Male group is 4.9.\n",
      "The average answer for INFLATION from the Female group is 7.4.\n",
      "\n",
      "The average answer for HOUSE PRICE CHANGE from the Male group is 4.6.\n",
      "The average answer for HOUSE PRICE CHANGE from the Female group is 6.5.\n",
      "\n",
      "The average answer for PROB STOCKS UP from the Male group is 45.9.\n",
      "The average answer for PROB STOCKS UP from the Female group is 38.0.\n"
     ]
    }
   ],
   "source": [
    "# 1. average for each expectations variable\n",
    "# Males Vs. Females\n",
    "\n",
    "# Create a function to calculate and print the average variables \n",
    "df_gender = df.groupby(['female'])\n",
    "def df_gender_calculation(variable):\n",
    "    variable_neat = variable.replace('_', ' ').upper()\n",
    "    variable_average = round(df_gender[variable].mean(),1)\n",
    "    variable_average = variable_average.rename({0.0: 'Male', 1.0: 'Female'})\n",
    "    variabledc = variable_average.to_dict()\n",
    "    for key, value in variabledc.items(): \n",
    "        print(f'The average answer for {variable_neat} from the {key} group is {value}.')\n",
    "\n",
    "df_gender_calculation(variable = 'inflation')\n",
    "print('')\n",
    "df_gender_calculation(variable = 'house_price_change')\n",
    "print('')\n",
    "df_gender_calculation(variable = 'prob_stocks_up')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f709a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average answer for INFLATION from the college educated group is 5.5.\n",
      "The average answer for INFLATION from the non college educated group is 16.3.\n",
      "\n",
      "The average answer for HOUSE PRICE CHANGE from the college educated group is 5.1.\n",
      "The average answer for HOUSE PRICE CHANGE from the non college educated group is 8.9.\n",
      "\n",
      "The average answer for PROB STOCKS UP from the college educated group is 43.0.\n",
      "The average answer for PROB STOCKS UP from the non college educated group is 34.3.\n"
     ]
    }
   ],
   "source": [
    "# non-college and college\n",
    "df_college = df[df['educ']>2]\n",
    "df_non_college= df[df['educ']<2]\n",
    "\n",
    "def df_college_calculation(variable):\n",
    "    variable_neat = variable.replace('_', ' ').upper()\n",
    "    df_educ ={}\n",
    "    variable_averagec = round(df_college[variable].mean(), 1)\n",
    "    variable_averagenc = round(df_non_college[variable].mean(),1)\n",
    "    df_educ['college educated'] = variable_averagec\n",
    "    df_educ['non college educated'] = variable_averagenc\n",
    "    for key, value in df_educ.items():\n",
    "        print(f'The average answer for {variable_neat} from the {key} group is {value}.')\n",
    "\n",
    "df_college_calculation(variable = 'inflation')\n",
    "print('')\n",
    "df_college_calculation(variable = 'house_price_change')\n",
    "print('')\n",
    "df_college_calculation(variable = 'prob_stocks_up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564be27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average answer for INFLATION from the high numeracy group is 8.2.\n",
      "The average answer for INFLATION from the low numeracy group is 14.1.\n",
      " \n",
      "The average answer for HOUSE PRICE CHANGE from the high numeracy group is 6.2.\n",
      "The average answer for HOUSE PRICE CHANGE from the low numeracy group is 12.2.\n",
      "\n",
      "The average answer for PROB STOCKS UP from the high numeracy group is 47.8.\n",
      "The average answer for PROB STOCKS UP from the low numeracy group is 41.5.\n"
     ]
    }
   ],
   "source": [
    "#low vs high numeracy\n",
    "# calculate average numeracy for each person\n",
    "columns= ['num_lit_q1_correct',\n",
    " 'num_lit_q2_correct',\n",
    " 'num_lit_q3_correct',\n",
    " 'num_lit_q5_correct',\n",
    " 'num_lit_q6_correct',\n",
    " 'num_lit_q8_correct',\n",
    " 'num_lit_q9_correct']\n",
    "df['Numeracy'] = df[columns].mean(axis = 1)\n",
    "\n",
    "#divide between high and low numeracy\n",
    "df_high = df[df['Numeracy']>0.5]\n",
    "df_low = df[df['Numeracy']<0.5]\n",
    "\n",
    "#function to calculate average for each variable\n",
    "def df_numeracy_calculation(variable):\n",
    "    variable_neat = variable.replace('_', ' ').upper()\n",
    "    df_num ={}\n",
    "    variable_averageh = round(df_high[variable].mean(), 1)\n",
    "    variable_averagel = round(df_low[variable].mean(),1)\n",
    "    df_num['high numeracy'] = variable_averageh\n",
    "    df_num['low numeracy'] = variable_averagel\n",
    "    for key, value in df_num.items():\n",
    "        print(f'The average answer for {variable_neat} from the {key} group is {value}.')\n",
    "\n",
    "df_numeracy_calculation(variable = 'inflation')\n",
    "print(' ')\n",
    "df_numeracy_calculation(variable = 'house_price_change')\n",
    "print('')\n",
    "df_numeracy_calculation(variable = 'prob_stocks_up')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21f9a8",
   "metadata": {},
   "source": [
    "Part 4\n",
    "\n",
    "To answer the governor’s second set of questions, you need to investigate how average expectations\n",
    "evolved over time for the period of 2015-2024 covered by the sample.\n",
    "For each grouping variable (female, college, num_lit_high):\n",
    "1. Collapse the data to monthly averages for each of the expectation variables (inflation, house prices,\n",
    "stock market) for each group (e.g., for males vs. females).\n",
    "2. Create a figure with three vertically stacked panels (one panel per expectation variable). Each\n",
    "panel should show the group time series (two series per panel, e.g., males vs. females) with time\n",
    "on the x-axis.\n",
    "3. The governor wants to know how expectations reacted to important geopolitical events. Add\n",
    "vertical lines and annotations to each panel indicating the following events:\n",
    "• Trump elected US president for the first time (November 8, 2016)\n",
    "• COVID-19 pandemic goes global (February 1, 2020)\n",
    "• Biden elected US president (November 3, 2020)\n",
    "• Russia’s full-scale invasion of Ukraine (February 24, 2022)\n",
    "• Nobel Prize in Literature awarded to Jon Fosse (October 3, 2023)\n",
    "• Trump elected US president for the second time (November 5, 2024)\n",
    "Which events had sizeable effects on expectations? Can you detect differences in how different\n",
    "groups adjusted their expectations?\n",
    "The complete analysis should produce three figures, each with three panels, each panel containing two\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095df410",
   "metadata": {},
   "source": [
    "Part 5\n",
    "\n",
    "Finally, the governor is interested in whether people’s expectations indicate realized future inflation or\n",
    "simply reflect past inflation experienced when answering the survey.\n",
    "To answer this question, you first need to obtain data on realized inflation. A colleague has already\n",
    "downloaded data on the level of the Consumer Price Index (CPI) from FRED and stored it as a CSV file\n",
    "in the data/ folder.\n",
    "1. First, compare expectations to realized future inflation:\n",
    "1. Using this monthly CPI data, compute the realized inflation over the next 12 months; i.e., for\n",
    "each month t compute the forward-looking annual inflation as\n",
    "In f lationt = CPIt+12 −CPIt\n",
    "CPIt\n",
    "×100\n",
    "2. Merge this inflation measure with the monthly averages by gender from Part 4. Specifically,\n",
    "match the average expected inflation by gender i in month t from the SCE, Ex pIn f lationit,\n",
    "with the forward-looking inflation measure In f lationt from the CPI data.\n",
    "3. Create a figure with two panels (one per gender), each showing a scatter plot of realized\n",
    "future inflation (y-axis) versus average expected inflation by gender.\n",
    "Compute the correlation between expected and realized inflation for each gender and add\n",
    "the correlation coefficient as text to the corresponding panel.\n",
    "4\n",
    "2. Repeat steps 1–3, but instead of forward-looking inflation, compute realized inflation over the past\n",
    "12 months:\n",
    "In f lationt = CPIt −CPIt−12\n",
    "CPIt−12\n",
    "×100\n",
    "Do you find differences in these correlation coefficients? What do these results say about how individuals\n",
    "form beliefs about inflation? Are there notable gender differences?\n",
    "Note: In this part, use monthly data only; individual-level SCE data is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290b49d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
